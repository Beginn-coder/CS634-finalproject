{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10ead3-d66f-4a13-9b6d-387f403fa5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f08324-7687-4ab9-95e8-9708af2aadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled dataset (assuming you have already saved it earlier as 'sampled_dataset.csv')\n",
    "dataset_sampled = pd.read_csv('sampled_dataset.csv')\n",
    "\n",
    "# Store 'url' column separately if it exists\n",
    "if 'url' in dataset_sampled.columns:\n",
    "    url_data = dataset_sampled['url'].copy()  # Copy 'url' column for later use\n",
    "    print(\"Vectorizing 'url' column...\")\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_urls_vectorized = vectorizer.fit_transform(url_data).toarray()\n",
    "    dataset_sampled = dataset_sampled.drop(columns=['url'])\n",
    "    X = np.hstack((dataset_sampled.iloc[:, :-1].values, X_urls_vectorized))\n",
    "else:\n",
    "    print(\"The 'url' column is not present in the dataset.\")\n",
    "    X = dataset_sampled.iloc[:, :-1].values  # Use only other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03e1b2-ad65-4ec5-8d3c-34f931a07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Split Dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84db4ec-1099-464c-baa6-48e5709261e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    \n",
    "     # Metrics using formulas\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN)  # True Positive Rate (Recall)\n",
    "    specificity = TN / (TN + FP)  # True Negative Rate (Specificity)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) != 0 else 0\n",
    "    error_rate = (FP + FN) / (TP + TN + FP + FN)\n",
    "    bacc = (sensitivity + specificity) / 2\n",
    "    fpr = FP / (FP + TN)  # False Positive Rate\n",
    "    fnr = FN / (FN + TP)  # False Negative Rate\n",
    "    brier_score = brier_score_loss(y_true, y_pred)\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    # Brier Skill Score (BSS)\n",
    "    baseline_brier_score = brier_score_loss(y_true, np.ones_like(y_true) * y_true.mean())\n",
    "    bss = 1 - (brier_score / baseline_brier_score) if baseline_brier_score != 0 else 0\n",
    "    \n",
    "    # Heidke Skill Score (HSS)\n",
    "    hss_numerator = 2 * (TP * TN - FP * FN)\n",
    "    hss_denominator = (TP + FP) * (FP + TN) + (TN + FN) * (FN + TP)\n",
    "    hss = hss_numerator / hss_denominator if hss_denominator != 0 else 0  # Avoid division by zero\n",
    "    \n",
    "    # True Skill Statistics (TSS)\n",
    "    tss = sensitivity + specificity - 1\n",
    "\n",
    "    return {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
    "        'Accuracy': accuracy, 'Sensitivity (TPR)': sensitivity, 'Specificity (TNR)': specificity,\n",
    "        'Precision': precision, 'F1 Score': f1, 'Error Rate': error_rate,\n",
    "        'Balanced Accuracy (BACC)': bacc, 'FPR': fpr, 'FNR': fnr,\n",
    "        'Brier Score (BS)': brier_score, 'Brier Skill Score (BSS)': bss, 'AUC': auc_score,\n",
    "        'HSS': hss, 'TSS': tss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75f229-9d2b-4c31-979f-027d4caddb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "svm_classifier = SVC(kernel='linear', random_state=0, probability=True)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "svm_metrics = calculate_metrics(y_test, y_pred_svm)\n",
    "print(\"SVM Metrics:\")\n",
    "for metric, value in svm_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0c1dd-fd8b-4afc-9493-3add98c0c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_metrics = calculate_metrics(y_test, y_pred_rf)\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed6153-aeb7-4bf6-9692-d5876f91b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation for Random Forest\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "kf_metrics_list = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_kf, X_test_kf = X[train_index], X[test_index]\n",
    "    y_train_kf, y_test_kf = y[train_index], y[test_index]\n",
    "\n",
    "    # Feature Scaling\n",
    "    X_train_kf = sc.fit_transform(X_train_kf)\n",
    "    X_test_kf = sc.transform(X_test_kf)\n",
    "\n",
    "    # Label Encoding\n",
    "    y_train_kf = le.fit_transform(y_train_kf)\n",
    "    y_test_kf = le.transform(y_test_kf)\n",
    "\n",
    "    rf_classifier.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = rf_classifier.predict(X_test_kf)\n",
    "\n",
    "    metrics_kf = calculate_metrics(y_test_kf, y_pred_kf)\n",
    "    kf_metrics_list.append(metrics_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56021f26-0b33-4572-82c8-d40e09e6db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics across all folds\n",
    "avg_metrics = {key: np.mean([metrics[key] for metrics in kf_metrics_list]) for key in kf_metrics_list[0]}\n",
    "print(\"\\nAverage Metrics over 10-Fold Cross-Validation:\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeffdc1-c2f3-40f9-b47c-292802d17784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model with try-except and debugging prints\n",
    "try:\n",
    "    max_features = 12000  # Adjust as needed\n",
    "    max_length = 100  # Adjust based on URL length or padding requirements\n",
    "\n",
    "    if 'url_data' in locals():  # Check if 'url_data' was stored\n",
    "        print(\"Vectorizing 'url' data for LSTM...\")\n",
    "        X_vectorized = vectorizer.fit_transform(url_data).toarray()\n",
    "\n",
    "        print(\"Splitting data into train and test sets for LSTM...\")\n",
    "        X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n",
    "            X_vectorized, y, test_size=0.25, random_state=0\n",
    "        )\n",
    "\n",
    "        # Ensure y_train_lstm and y_test_lstm are numeric\n",
    "        le_lstm = LabelEncoder()\n",
    "        y_train_lstm = le_lstm.fit_transform(y_train_lstm)\n",
    "        y_test_lstm = le_lstm.transform(y_test_lstm)\n",
    "\n",
    "        print(\"Padding sequences for LSTM...\")\n",
    "        X_train_lstm = pad_sequences(X_train_lstm, maxlen=max_length)\n",
    "        X_test_lstm = pad_sequences(X_test_lstm, maxlen=max_length)\n",
    "\n",
    "        # Convert to float32\n",
    "        X_train_lstm = X_train_lstm.astype(np.float32)\n",
    "        X_test_lstm = X_test_lstm.astype(np.float32)\n",
    "\n",
    "        print(\"Building LSTM model...\")\n",
    "        lstm_model = Sequential()\n",
    "        lstm_model.add(Embedding(input_dim=max_features, output_dim=128, input_length=max_length))\n",
    "        lstm_model.add(SpatialDropout1D(0.2))\n",
    "        lstm_model.add(LSTM(100))\n",
    "        lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        print(\"Training LSTM model...\")\n",
    "        lstm_model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=64, verbose=2)\n",
    "\n",
    "        print(\"Evaluating LSTM model...\")\n",
    "        y_pred_lstm = (lstm_model.predict(X_test_lstm) > 0.5).astype(\"int32\")\n",
    "        lstm_metrics = calculate_metrics(y_test_lstm, y_pred_lstm.flatten())\n",
    "        print(\"\\nLSTM Metrics:\")\n",
    "        for metric, value in lstm_metrics.items():\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "    else:\n",
    "        print(\"LSTM processing skipped as 'url' data is not available.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during the LSTM block execution:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca65538-cfc2-4303-a7b1-47bfcb1875f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(y_test), index=np.unique(y_test))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 10})\n",
    "    plt.title(title)\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred_svm), \"SVM Confusion Matrix Heat Map\")\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred_rf), \"Random Forest Confusion Matrix Heat Map\")\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred_rf), \"LSTM Confusion Matrix Heat Map\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
